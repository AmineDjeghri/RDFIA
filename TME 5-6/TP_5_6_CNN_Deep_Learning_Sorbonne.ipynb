{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TP_5_6_CNN_Deep_Learning_Sorbonne.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VgWb11WT-07r"},"source":["\n","## Avant de commencer le TP, \n","- vérifiez que vous êtes sur un environnement GPU et python 3 : \n","  \n","  Éxecution -> Modifier le type d'éxecution -> Type d'éxecution = python2, Accélerateur matériel = GPU\n","\n","- Fichier -> Sauvegarder une copie dans mon drive"]},{"cell_type":"code","metadata":{"id":"R1EC2TEj97Nn","executionInfo":{"status":"ok","timestamp":1605716388484,"user_tz":-60,"elapsed":2331,"user":{"displayName":"Amine Djeghri","photoUrl":"","userId":"06388183709028540430"}}},"source":["# It will reload all changed modules every time before executing a new line\n","%load_ext autoreload\n","%autoreload 2\n","\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","import os\n","os.chdir(\"/content/gdrive/My Drive/git/RDFIA/TME 5-6\")\n","!ls"]},{"cell_type":"code","metadata":{"id":"ac5Js1iML3d_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605713513640,"user_tz":-60,"elapsed":6534,"user":{"displayName":"Amine Djeghri","photoUrl":"","userId":"06388183709028540430"}},"outputId":"0e4cfcf4-5bb7-426d-a622-1303d702f194"},"source":["!git clone https://github.com/cdancette/deep-learning-polytech-tp6-7.git"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Cloning into 'deep-learning-polytech-tp6-7'...\n","remote: Enumerating objects: 11, done.\u001b[K\n","remote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (9/9), done.\u001b[K\n","remote: Total 19 (delta 2), reused 7 (delta 1), pack-reused 8\u001b[K\n","Unpacking objects: 100% (19/19), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CTv6tOOdOCr9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605713513647,"user_tz":-60,"elapsed":5864,"user":{"displayName":"Amine Djeghri","photoUrl":"","userId":"06388183709028540430"}},"outputId":"7b3417bc-20e0-4014-9306-a52cd50fbd35"},"source":["cd deep-learning-polytech-tp6-7"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/deep-learning-polytech-tp6-7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8I7lgAEJvPCh"},"source":["import argparse\n","import os\n","import time\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim\n","import torch.utils.data\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","from tme6 import *\n","\n","PRINT_INTERVAL = 200\n","PATH=\"datasets\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3xVkUxvwy6a0"},"source":["class ConvNet(nn.Module):\n","    \"\"\"\n","    Cette classe contient la structure du réseau de neurones\n","    \"\"\"\n","\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        # On défini d'abord les couches de convolution et de pooling comme un\n","        # groupe de couches `self.features`\n","        self.features = nn.Sequential(\n","            nn.Conv2d(1, 6, (5, 5), stride=1, padding=2),\n","            nn.Tanh(),\n","            nn.MaxPool2d((2, 2), stride=2, padding=0),\n","            nn.Conv2d(6, 16, (5, 5), stride=1, padding=0),\n","            nn.Tanh(),\n","            nn.MaxPool2d((2, 2), stride=2, padding=0),\n","        )\n","        # On défini les couches fully connected comme un groupe de couches\n","        # `self.classifier`\n","        self.classifier = nn.Sequential(\n","            nn.Linear(400, 120),\n","            nn.Tanh(),\n","            nn.Linear(120, 84),\n","            nn.Tanh(),\n","            nn.Linear(84, 10)\n","            # Rappel : Le softmax est inclus dans la loss, ne pas le mettre ici\n","        )\n","\n","    # méthode appelée quand on applique le réseau à un batch d'input\n","    def forward(self, input):\n","        bsize = input.size(0) # taille du batch\n","        output = self.features(input) # on calcule la sortie des conv\n","        output = output.view(bsize, -1) # on applati les feature map 2D en un\n","                                        # vecteur 1D pour chaque input\n","        output = self.classifier(output) # on calcule la sortie des fc\n","        return output\n","\n","\n","\n","def get_dataset(batch_size, cuda=False):\n","    \"\"\"\n","    Cette fonction charge le dataset et effectue des transformations sur chaqu\n","    image (listées dans `transform=...`).\n","    \"\"\"\n","    train_dataset = datasets.MNIST(PATH, train=True, download=True,\n","        transform=transforms.Compose([\n","            transforms.ToTensor()\n","        ]))\n","    val_dataset = datasets.MNIST(PATH, train=False, download=True,\n","        transform=transforms.Compose([\n","            transforms.ToTensor()\n","        ]))\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset,\n","                        batch_size=batch_size, shuffle=True, pin_memory=cuda, num_workers=2)\n","    val_loader = torch.utils.data.DataLoader(val_dataset,\n","                        batch_size=batch_size, shuffle=False, pin_memory=cuda, num_workers=2)\n","\n","    return train_loader, val_loader\n","\n","\n","\n","def epoch(data, model, criterion, optimizer=None, cuda=False):\n","    \"\"\"\n","    Fait une passe (appelée epoch en anglais) sur les données `data` avec le\n","    modèle `model`. Evalue `criterion` comme loss.\n","    Si `optimizer` est fourni, effectue une epoch d'apprentissage en utilisant\n","    l'optimiseur donné, sinon, effectue une epoch d'évaluation (pas de backward)\n","    du modèle.\n","    \"\"\"\n","\n","    # indique si le modele est en mode eval ou train (certaines couches se\n","    # comportent différemment en train et en eval)\n","    model.eval() if optimizer is None else model.train()\n","\n","    # objets pour stocker les moyennes des metriques\n","    avg_loss = AverageMeter()\n","    avg_top1_acc = AverageMeter()\n","    avg_top5_acc = AverageMeter()\n","    avg_batch_time = AverageMeter()\n","    global loss_plot\n","\n","    # on itere sur les batchs du dataset\n","    tic = time.time()\n","    for i, (input, target) in enumerate(data):\n","\n","        if cuda: # si on fait du GPU, passage en CUDA\n","            input = input.cuda()\n","            target = target.cuda()\n","\n","        # forward\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # backward si on est en \"train\"\n","        if optimizer:\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","        # calcul des metriques\n","        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n","        batch_time = time.time() - tic\n","        tic = time.time()\n","\n","        # mise a jour des moyennes\n","        avg_loss.update(loss.item())\n","        avg_top1_acc.update(prec1.item())\n","        avg_top5_acc.update(prec5.item())\n","        avg_batch_time.update(batch_time)\n","        if optimizer:\n","            loss_plot.update(avg_loss.val)\n","        # affichage des infos\n","        if i % PRINT_INTERVAL == 0:\n","            print('[{0:s} Batch {1:03d}/{2:03d}]\\t'\n","                  'Time {batch_time.val:.3f}s ({batch_time.avg:.3f}s)\\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n","                  'Prec@1 {top1.val:5.1f} ({top1.avg:5.1f})\\t'\n","                  'Prec@5 {top5.val:5.1f} ({top5.avg:5.1f})'.format(\n","                   \"EVAL\" if optimizer is None else \"TRAIN\", i, len(data), batch_time=avg_batch_time, loss=avg_loss,\n","                   top1=avg_top1_acc, top5=avg_top5_acc))\n","            if optimizer:\n","                loss_plot.plot()\n","\n","    # Affichage des infos sur l'epoch\n","    print('\\n===============> Total time {batch_time:d}s\\t'\n","          'Avg loss {loss.avg:.4f}\\t'\n","          'Avg Prec@1 {top1.avg:5.2f} %\\t'\n","          'Avg Prec@5 {top5.avg:5.2f} %\\n'.format(\n","           batch_time=int(avg_batch_time.sum), loss=avg_loss,\n","           top1=avg_top1_acc, top5=avg_top5_acc))\n","\n","    return avg_top1_acc, avg_top5_acc, avg_loss\n","\n","\n","def main(batch_size=128, lr=0.1, epochs=5, cuda=False):\n","\n","    # ex de params :\n","    #   {\"batch_size\": 128, \"epochs\": 5, \"lr\": 0.1}\n","    \n","    # define model, loss, optim\n","    model = ConvNet()\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.SGD(model.parameters(), lr)\n","\n","    if cuda: # si on fait du GPU, passage en CUDA\n","        cudnn.benchmark = True\n","        model = model.cuda()\n","        criterion = criterion.cuda()\n","\n","    # On récupère les données\n","    train, test = get_dataset(batch_size, cuda)\n","\n","    # init plots\n","    plot = AccLossPlot()\n","    global loss_plot\n","    loss_plot = TrainLossPlot()\n","\n","    # On itère sur les epochs\n","    for i in range(epochs):\n","        print(\"=================\\n=== EPOCH \"+str(i+1)+\" =====\\n=================\\n\")\n","        # Phase de train\n","        top1_acc, avg_top5_acc, loss = epoch(train, model, criterion, optimizer, cuda)\n","        # Phase d'evaluation\n","        top1_acc_test, top5_acc_test, loss_test = epoch(test, model, criterion, cuda=cuda)\n","        # plot\n","        plot.update(loss.avg, loss_test.avg, top1_acc.avg, top1_acc_test.avg)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uXoiJsO0PI5C"},"source":["main(128, 0.1, cuda=True)"],"execution_count":null,"outputs":[]}]}